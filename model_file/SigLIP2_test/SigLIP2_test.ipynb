{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80755102",
   "metadata": {},
   "source": [
    "## (A) ê¸°ì¡´ SigLIP2 ëª¨ë¸ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f920807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì˜ˆì¸¡ ê²°ê³¼:\n",
      "1. Label: í°ìƒ‰ì˜ ë¶„ë§ì´ ë“¤ì–´ìˆëŠ” ìƒë¶€ ì´ˆë¡ìƒ‰, í•˜ë¶€ ë¯¸í™©ìƒ‰ì˜ ê²½ì§ˆìº¡ìŠì œ, ì•ë©´ 'ë§ˆí¬ ELT', ë’·ë©´ '' ë¼ê³  ì í˜€ ìˆìŒ\n",
      "   Score: 0.2955\n",
      "2. Label: ë¯¸í™©ìƒ‰ì˜ ì›í˜• ì •ì œ, ì•ë©´ 'YH', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ\n",
      "   Score: 0.0056\n",
      "3. Label: ë°±ìƒ‰ì˜ ì›í˜• ì •ì œ, ì•ë©´ 'YH', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ\n",
      "   Score: 0.0008\n",
      "4. Label: ë°±ìƒ‰ì˜ ì›í˜•í•„ë¦„ì œí”¼ì •, ì•ë©´ 'SJÎ›', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ\n",
      "   Score: 0.0008\n",
      "5. Label: í°ìƒ‰ ë˜ëŠ” ê±°ì˜ í°ìƒ‰ì˜ ì›í˜• ì •ì œ, ì•ë©´ 'ë§ˆí¬ë¶„í• ì„ ST', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ\n",
      "   Score: 0.0005\n",
      "6. Label: ì¥ë°©í˜• ë°±ìƒ‰ ì •ì œ, ì•ë©´ 'LDIë¶„í• ì„ LDI', ë’·ë©´ 'ë¶„í• ì„ 'ë¼ê³  ì í˜€ ìˆìŒ\n",
      "   Score: 0.0003\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    model=\"google/siglip2-large-patch16-256\",\n",
    "    task=\"zero-shot-image-classification\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# í›„ë³´ ë¼ë²¨ ëª©ë¡ (í…ìŠ¤íŠ¸ë¡œ ëœ í´ë˜ìŠ¤ ì´ë¦„ë“¤)\n",
    "labels = [\"í°ìƒ‰ì˜ ë¶„ë§ì´ ë“¤ì–´ìˆëŠ” ìƒë¶€ ì´ˆë¡ìƒ‰, í•˜ë¶€ ë¯¸í™©ìƒ‰ì˜ ê²½ì§ˆìº¡ìŠì œ, ì•ë©´ 'ë§ˆí¬ ELT', ë’·ë©´ '' ë¼ê³  ì í˜€ ìˆìŒ\", \n",
    "          \"ë°±ìƒ‰ì˜ ì›í˜•í•„ë¦„ì œí”¼ì •, ì•ë©´ 'SJÎ›', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ\",\n",
    "          \"ë¯¸í™©ìƒ‰ì˜ ì›í˜• ì •ì œ, ì•ë©´ 'YH', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ\",\n",
    "          \"ë°±ìƒ‰ì˜ ì›í˜• ì •ì œ, ì•ë©´ 'YH', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ\",\n",
    "          \"í°ìƒ‰ ë˜ëŠ” ê±°ì˜ í°ìƒ‰ì˜ ì›í˜• ì •ì œ, ì•ë©´ 'ë§ˆí¬ë¶„í• ì„ ST', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ\",\n",
    "          \"ì¥ë°©í˜• ë°±ìƒ‰ ì •ì œ, ì•ë©´ 'LDIë¶„í• ì„ LDI', ë’·ë©´ 'ë¶„í• ì„ 'ë¼ê³  ì í˜€ ìˆìŒ\"]  # ì´ 4000ê°œ ê°€ëŠ¥\n",
    "\n",
    "# ì•Œì•½ ì´ë¯¸ì§€ì— ëŒ€í•´ ì˜ˆì¸¡\n",
    "result = pipe(r\"C:\\Users\\302-09\\Desktop\\ê¹¡í†µ\\myì•Œì•½\\KakaoTalk_20250612_144853880_02.jpg\", candidate_labels=labels)\n",
    "print(\"ğŸ” ì˜ˆì¸¡ ê²°ê³¼:\")\n",
    "for i, res in enumerate(result, 1):\n",
    "    print(f\"{i}. Label: {res['label']}\")\n",
    "    print(f\"   Score: {res['score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d797cede",
   "metadata": {},
   "source": [
    "## (B) ê¸°ì¡´ SigLIP2 ëª¨ë¸ì— ì•Œì•½ì„ í•™ìŠµ\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef334a40",
   "metadata": {},
   "source": [
    "## (C) ê¸°ì¡´ SigLIP2 ëª¨ë¸ + ì„ë² ë”©, ì½”ì‚¬ì¸ ìœ ì‚¬ë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd1a989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì˜ˆì¸¡ ê²°ê³¼ (Top-3)\n",
      "- ë°±ìƒ‰ì˜ ì›í˜• ì •ì œ, ì•ë©´ 'YH', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ (score: 0.0886)\n",
      "- í°ìƒ‰ ë˜ëŠ” ê±°ì˜ í°ìƒ‰ì˜ ì›í˜• ì •ì œ, ì•ë©´ 'ë§ˆí¬ë¶„í• ì„ ST', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ (score: 0.0792)\n",
      "- ë¯¸í™©ìƒ‰ì˜ ì›í˜• ì •ì œ, ì•ë©´ 'YH', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ (score: 0.0698)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModel\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# ëª¨ë¸ ì¤€ë¹„ (ì‚¬ì „ í•™ìŠµëœ SigLIP2)\n",
    "model_name = \"google/siglip2-large-patch16-256\"\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# ì´ë¯¸ì§€ ì„ë² ë”© ì¶”ì¶œ í•¨ìˆ˜\n",
    "def get_image_embedding(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        img_embed = model.get_image_features(**inputs)\n",
    "    return img_embed / img_embed.norm(dim=-1, keepdim=True)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì„ë² ë”© ì¶”ì¶œ í•¨ìˆ˜\n",
    "def get_text_embeddings(text_list):\n",
    "    inputs = processor(text=text_list, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        text_embeds = model.get_text_features(**inputs)\n",
    "    return text_embeds / text_embeds.norm(dim=-1, keepdim=True)\n",
    "\n",
    "# ğŸ”¹ í›„ë³´ í…ìŠ¤íŠ¸ ì„¤ëª…ë“¤ (ì˜ˆ: seq ê¸°ë°˜ ì„¤ëª…ë“¤)\n",
    "text_labels = [\"í°ìƒ‰ì˜ ë¶„ë§ì´ ë“¤ì–´ìˆëŠ” ìƒë¶€ ì´ˆë¡ìƒ‰, í•˜ë¶€ ë¯¸í™©ìƒ‰ì˜ ê²½ì§ˆìº¡ìŠì œ, ì•ë©´ 'ë§ˆí¬ ELT', ë’·ë©´ '' ë¼ê³  ì í˜€ ìˆìŒ\", \n",
    "          \"ë°±ìƒ‰ì˜ ì›í˜•í•„ë¦„ì œí”¼ì •, ì•ë©´ 'SJÎ›', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ\",\n",
    "          \"ë¯¸í™©ìƒ‰ì˜ ì›í˜• ì •ì œ, ì•ë©´ 'YH', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ\",\n",
    "          \"ë°±ìƒ‰ì˜ ì›í˜• ì •ì œ, ì•ë©´ 'YH', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ\",\n",
    "          \"í°ìƒ‰ ë˜ëŠ” ê±°ì˜ í°ìƒ‰ì˜ ì›í˜• ì •ì œ, ì•ë©´ 'ë§ˆí¬ë¶„í• ì„ ST', ë’·ë©´ ''ë¼ê³  ì í˜€ ìˆìŒ\",\n",
    "          \"ì¥ë°©í˜• ë°±ìƒ‰ ì •ì œ, ì•ë©´ 'LDIë¶„í• ì„ LDI', ë’·ë©´ 'ë¶„í• ì„ 'ë¼ê³  ì í˜€ ìˆìŒ\"\n",
    "          ]\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì„ë² ë”© (1íšŒë§Œ)\n",
    "text_embeds = get_text_embeddings(text_labels)\n",
    "\n",
    "# ğŸ”¹ ì˜ˆì¸¡í•  ì´ë¯¸ì§€\n",
    "img_path = r\"C:\\Users\\302-09\\Desktop\\ê¹¡í†µ\\myì•Œì•½\\KakaoTalk_20250612_144853880_02.jpg\"\n",
    "img_embed = get_image_embedding(img_path)\n",
    "\n",
    "# ğŸ” ìœ ì‚¬ë„ ê³„ì‚°\n",
    "similarities = (img_embed @ text_embeds.T).squeeze(0)\n",
    "top_k = torch.topk(similarities, k=3)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ğŸ” ì˜ˆì¸¡ ê²°ê³¼ (Top-3)\")\n",
    "for idx, score in zip(top_k.indices, top_k.values):\n",
    "    print(f\"- {text_labels[idx]} (score: {score:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
